{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T01:37:03.535407Z",
     "start_time": "2019-12-02T01:37:00.179771Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras, feature_column\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T01:37:30.885726Z",
     "start_time": "2019-12-02T01:37:30.057196Z"
    }
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"../data/train_values.csv\", index_col = 'building_id')\n",
    "y = pd.read_csv(\"../data/train_labels.csv\", index_col = 'building_id').pop('damage_grade')\n",
    "\n",
    "# Adjust percentage value to range [0, 1]\n",
    "for header in [\"area_percentage\", \"height_percentage\"]:\n",
    "    X[header] = X[header] / 100.\n",
    "# Adjust label to range [0, 2]\n",
    "y -= 1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T01:37:33.359734Z",
     "start_time": "2019-12-02T01:37:33.356019Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208480 208480 training examples\n",
      "52121 52121 test examples\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(y_train), 'training examples')\n",
    "print(len(X_test), len(y_test), 'test examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(dataframe, labels, shuffle=True, batch_size=32):\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every feature: ['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id', 'count_floors_pre_eq', 'age', 'area_percentage', 'height_percentage', 'land_surface_condition', 'foundation_type', 'roof_type', 'ground_floor_type', 'other_floor_type', 'position', 'plan_configuration', 'has_superstructure_adobe_mud', 'has_superstructure_mud_mortar_stone', 'has_superstructure_stone_flag', 'has_superstructure_cement_mortar_stone', 'has_superstructure_mud_mortar_brick', 'has_superstructure_cement_mortar_brick', 'has_superstructure_timber', 'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered', 'has_superstructure_rc_engineered', 'has_superstructure_other', 'legal_ownership_status', 'count_families', 'has_secondary_use', 'has_secondary_use_agriculture', 'has_secondary_use_hotel', 'has_secondary_use_rental', 'has_secondary_use_institution', 'has_secondary_use_school', 'has_secondary_use_industry', 'has_secondary_use_health_post', 'has_secondary_use_gov_office', 'has_secondary_use_use_police', 'has_secondary_use_other']\n",
      "A batch of ages: tf.Tensor([ 5191 10579 10554  5710    65], shape=(5,), dtype=int32)\n",
      "A batch of targets: tf.Tensor([2 3 2 3 3], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for feature_batch, label_batch in train_ds.take(1):\n",
    "  print('Every feature:', list(feature_batch.keys()))\n",
    "  print('A batch of ages:', feature_batch['geo_level_3_id'])\n",
    "  print('A batch of targets:', label_batch )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "\n",
    "# numeric cols\n",
    "for header in [\"area_percentage\",\n",
    "              \"height_percentage\"]:\n",
    "    feature_columns.append(feature_column.numeric_column(header))\n",
    "\n",
    "# numeric embedding cols\n",
    "for (header, max_value) in [\n",
    "    (\"age\", 995),\n",
    "    (\"count_floors_pre_eq\", 9),\n",
    "    (\"count_families\", 9),\n",
    "    (\"geo_level_1_id\", 30),\n",
    "    (\"geo_level_2_id\", 1427),\n",
    "    (\"geo_level_3_id\", 12567)]:\n",
    "    one_hot = feature_column.categorical_column_with_identity(\n",
    "      header, num_buckets=max_value+2, default_value=max_value+1)\n",
    "    embedding = feature_column.embedding_column(one_hot, dimension=4)\n",
    "    feature_columns.append(embedding)\n",
    "\n",
    "# binary cols\n",
    "for header in ['has_superstructure_adobe_mud',\n",
    "       'has_superstructure_mud_mortar_stone', 'has_superstructure_stone_flag',\n",
    "       'has_superstructure_cement_mortar_stone',\n",
    "       'has_superstructure_mud_mortar_brick',\n",
    "       'has_superstructure_cement_mortar_brick', 'has_superstructure_timber',\n",
    "       'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered',\n",
    "       'has_superstructure_rc_engineered', 'has_superstructure_other',\n",
    "         'has_secondary_use',\n",
    "       'has_secondary_use_agriculture', 'has_secondary_use_hotel',\n",
    "       'has_secondary_use_rental', 'has_secondary_use_institution',\n",
    "       'has_secondary_use_school', 'has_secondary_use_industry',\n",
    "       'has_secondary_use_health_post', 'has_secondary_use_gov_office',\n",
    "       'has_secondary_use_use_police', 'has_secondary_use_other']:\n",
    "    one_hot = feature_column.categorical_column_with_identity(\n",
    "        header, num_buckets=2, default_value=0)\n",
    "    feature_columns.append(feature_column.indicator_column(one_hot))\n",
    "\n",
    "\n",
    "# categorical embedding cols\n",
    "for header in [\"land_surface_condition\", \"foundation_type\",\n",
    "                \"roof_type\", \"ground_floor_type\", \"other_floor_type\",\n",
    "                \"position\", \"plan_configuration\", 'legal_ownership_status']:\n",
    "    one_hot = feature_column.categorical_column_with_hash_bucket(header, hash_bucket_size=100)\n",
    "    embedding = feature_column.embedding_column(one_hot, dimension=4)\n",
    "    feature_columns.append(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NumericColumn(key='area_percentage', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='height_percentage', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " EmbeddingColumn(categorical_column=IdentityCategoricalColumn(key='age', number_buckets=997, default_value=996), dimension=4, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x1a92594650>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " EmbeddingColumn(categorical_column=IdentityCategoricalColumn(key='count_floors_pre_eq', number_buckets=11, default_value=10), dimension=4, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x1a9256e310>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " EmbeddingColumn(categorical_column=IdentityCategoricalColumn(key='count_families', number_buckets=11, default_value=10), dimension=4, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x1a9256e350>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " EmbeddingColumn(categorical_column=IdentityCategoricalColumn(key='geo_level_1_id', number_buckets=32, default_value=31), dimension=4, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x1a92597950>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " EmbeddingColumn(categorical_column=IdentityCategoricalColumn(key='geo_level_2_id', number_buckets=1429, default_value=1428), dimension=4, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x1a925abdd0>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " EmbeddingColumn(categorical_column=IdentityCategoricalColumn(key='geo_level_3_id', number_buckets=12569, default_value=12568), dimension=4, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x1a925abf90>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " IndicatorColumn(categorical_column=IdentityCategoricalColumn(key='has_superstructure_adobe_mud', number_buckets=2, default_value=0)),\n",
       " IndicatorColumn(categorical_column=IdentityCategoricalColumn(key='has_superstructure_mud_mortar_stone', number_buckets=2, default_value=0)),\n",
       " IndicatorColumn(categorical_column=IdentityCategoricalColumn(key='has_superstructure_stone_flag', number_buckets=2, default_value=0)),\n",
       " IndicatorColumn(categorical_column=IdentityCategoricalColumn(key='has_superstructure_cement_mortar_stone', number_buckets=2, default_value=0)),\n",
       " IndicatorColumn(categorical_column=IdentityCategoricalColumn(key='has_superstructure_mud_mortar_brick', number_buckets=2, default_value=0)),\n",
       " IndicatorColumn(categorical_column=IdentityCategoricalColumn(key='has_superstructure_cement_mortar_brick', number_buckets=2, default_value=0)),\n",
       " IndicatorColumn(categorical_column=IdentityCategoricalColumn(key='has_superstructure_timber', number_buckets=2, default_value=0)),\n",
       " IndicatorColumn(categorical_column=IdentityCategoricalColumn(key='has_superstructure_bamboo', number_buckets=2, default_value=0)),\n",
       " IndicatorColumn(categorical_column=IdentityCategoricalColumn(key='has_superstructure_rc_non_engineered', number_buckets=2, default_value=0)),\n",
       " IndicatorColumn(categorical_column=IdentityCategoricalColumn(key='has_superstructure_rc_engineered', number_buckets=2, default_value=0)),\n",
       " IndicatorColumn(categorical_column=IdentityCategoricalColumn(key='has_superstructure_other', number_buckets=2, default_value=0)),\n",
       " IndicatorColumn(categorical_column=IdentityCategoricalColumn(key='has_secondary_use', number_buckets=2, default_value=0)),\n",
       " IndicatorColumn(categorical_column=IdentityCategoricalColumn(key='has_secondary_use_agriculture', number_buckets=2, default_value=0)),\n",
       " IndicatorColumn(categorical_column=IdentityCategoricalColumn(key='has_secondary_use_hotel', number_buckets=2, default_value=0)),\n",
       " IndicatorColumn(categorical_column=IdentityCategoricalColumn(key='has_secondary_use_rental', number_buckets=2, default_value=0)),\n",
       " IndicatorColumn(categorical_column=IdentityCategoricalColumn(key='has_secondary_use_institution', number_buckets=2, default_value=0)),\n",
       " IndicatorColumn(categorical_column=IdentityCategoricalColumn(key='has_secondary_use_school', number_buckets=2, default_value=0)),\n",
       " IndicatorColumn(categorical_column=IdentityCategoricalColumn(key='has_secondary_use_industry', number_buckets=2, default_value=0)),\n",
       " IndicatorColumn(categorical_column=IdentityCategoricalColumn(key='has_secondary_use_health_post', number_buckets=2, default_value=0)),\n",
       " IndicatorColumn(categorical_column=IdentityCategoricalColumn(key='has_secondary_use_gov_office', number_buckets=2, default_value=0)),\n",
       " IndicatorColumn(categorical_column=IdentityCategoricalColumn(key='has_secondary_use_use_police', number_buckets=2, default_value=0)),\n",
       " IndicatorColumn(categorical_column=IdentityCategoricalColumn(key='has_secondary_use_other', number_buckets=2, default_value=0)),\n",
       " EmbeddingColumn(categorical_column=HashedCategoricalColumn(key='land_surface_condition', hash_bucket_size=100, dtype=tf.string), dimension=4, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x1a923cfad0>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " EmbeddingColumn(categorical_column=HashedCategoricalColumn(key='foundation_type', hash_bucket_size=100, dtype=tf.string), dimension=4, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x1a923235d0>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " EmbeddingColumn(categorical_column=HashedCategoricalColumn(key='roof_type', hash_bucket_size=100, dtype=tf.string), dimension=4, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x1a92334ed0>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " EmbeddingColumn(categorical_column=HashedCategoricalColumn(key='ground_floor_type', hash_bucket_size=100, dtype=tf.string), dimension=4, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x1a92546450>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " EmbeddingColumn(categorical_column=HashedCategoricalColumn(key='other_floor_type', hash_bucket_size=100, dtype=tf.string), dimension=4, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x1a92546cd0>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " EmbeddingColumn(categorical_column=HashedCategoricalColumn(key='position', hash_bucket_size=100, dtype=tf.string), dimension=4, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x1a92546810>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " EmbeddingColumn(categorical_column=HashedCategoricalColumn(key='plan_configuration', hash_bucket_size=100, dtype=tf.string), dimension=4, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x1a925463d0>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " EmbeddingColumn(categorical_column=HashedCategoricalColumn(key='legal_ownership_status', hash_bucket_size=100, dtype=tf.string), dimension=4, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x1a92546e90>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True)]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/xx/j9szjz0n3bn5nhwq1ms96lgjqp577y/T/tmp1gcey8mg\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/xx/j9szjz0n3bn5nhwq1ms96lgjqp577y/T/tmp1gcey8mg', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1a8e4c1cd0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "estimator = tf.estimator.DNNClassifier(\n",
    "    feature_columns=feature_columns,\n",
    "    hidden_units=[1024, 512, 512, 256, 256],\n",
    "    optimizer=\"Adam\",\n",
    "    n_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer hiddenlayer_0 is casting an input tensor from dtype float32 to the layer's dtype of float64, which is new behavior in TensorFlow 2.  The layer has dtype float64 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float64, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float32 by default, call `tf.keras.backend.set_floatx('float32')`. To change just this layer, pass dtype='float32' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/xx/j9szjz0n3bn5nhwq1ms96lgjqp577y/T/tmp1gcey8mg/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.0641019, step = 0\n",
      "INFO:tensorflow:global_step/sec: 9.42335\n",
      "INFO:tensorflow:loss = 0.8811115, step = 100 (10.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.9382\n",
      "INFO:tensorflow:loss = 0.7375692, step = 200 (5.015 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.7179\n",
      "INFO:tensorflow:loss = 0.8317565, step = 300 (5.072 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.8634\n",
      "INFO:tensorflow:loss = 0.5256318, step = 400 (5.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.2322\n",
      "INFO:tensorflow:loss = 0.6152409, step = 500 (4.941 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.8377\n",
      "INFO:tensorflow:loss = 0.82888806, step = 600 (5.042 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.2756\n",
      "INFO:tensorflow:loss = 1.0936209, step = 700 (5.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.1103\n",
      "INFO:tensorflow:loss = 0.60191596, step = 800 (4.973 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 900 into /var/folders/xx/j9szjz0n3bn5nhwq1ms96lgjqp577y/T/tmp1gcey8mg/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.6960882.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x1a8e4c1390>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.train(input_fn=lambda: df_to_dataset(X_train, y_train, shuffle=True, batch_size=32),\n",
    "steps=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer hiddenlayer_0 is casting an input tensor from dtype float32 to the layer's dtype of float64, which is new behavior in TensorFlow 2.  The layer has dtype float64 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float64, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float32 by default, call `tf.keras.backend.set_floatx('float32')`. To change just this layer, pass dtype='float32' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-01T16:17:23Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/xx/j9szjz0n3bn5nhwq1ms96lgjqp577y/T/tmp1gcey8mg/model.ckpt-900\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-01-16:17:58\n",
      "INFO:tensorflow:Saving dict for global step 900: accuracy = 0.6734521593983231, average_loss = 0.7105239680559127, global_step = 900, loss = 0.71051645\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 900: /var/folders/xx/j9szjz0n3bn5nhwq1ms96lgjqp577y/T/tmp1gcey8mg/model.ckpt-900\n"
     ]
    }
   ],
   "source": [
    "metrics = estimator.evaluate(input_fn=lambda: df_to_dataset(X_test, y_test, shuffle=False, batch_size=32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6734521593983231,\n",
       " 'average_loss': 0.7105239680559127,\n",
       " 'loss': 0.71051645,\n",
       " 'global_step': 900}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
